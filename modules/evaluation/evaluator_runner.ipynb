{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22aee66-7a3f-4a96-a1a9-bcc6ab04cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "base_folder = Path(\"/home/automl/git/iot-threat-classifier/2025-06-28/Input_Multiclass\")\n",
    "\n",
    "dispatcher_filename = Path(os.path.join(base_folder, \"start\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee1f5b-7265-4caa-a23b-7d15002507c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "def now():\n",
    "    now = datetime.now()\n",
    "    yyyymmdd_hhmmss_part = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    ms_part = f'{int(now.microsecond / 1000):03d}'\n",
    "    return f'{yyyymmdd_hhmmss_part},{ms_part}'\n",
    "\n",
    "while not dispatcher_filename.exists():\n",
    "    print(f'[{now()}] Dispatcher file does not exist; sleeping...')\n",
    "    sleep(300)\n",
    "\n",
    "print(f'[{now()}] Dispatcher file EXISTS; starting...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73dbf8-fa7a-4ab0-bd01-25259c733910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_results(results_filename):\n",
    "    df = pd.read_excel(results_filename)\n",
    "    try:\n",
    "        row = df.loc[df['f1_score_abs'].idxmax(), ['Unnamed: 0', 'f1_score_abs']]\n",
    "        max_config = str(row['Unnamed: 0'])\n",
    "        max_f1_weighted = f\"{float(row['f1_score_abs']):.6f}\"\n",
    "    except Exception:\n",
    "        max_config = None\n",
    "        max_f1_weighted = str(np.nan)\n",
    "    cfg_str = f\"{max_config if max_config else 'N/A':<8}\"\n",
    "    f1_str = f\"{max_f1_weighted if max_f1_weighted not in ['nan', None] else 'N/A':<8}\"\n",
    "    return cfg_str, f1_str\n",
    "\n",
    "def parse_exception(e):\n",
    "    try:\n",
    "        return str(e).split(\"\\n\")[-2]\n",
    "    except:\n",
    "        return \"unknown error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b18448-632e-471a-868e-199d69d5008b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import papermill as pm\n",
    "\n",
    "errors = {}\n",
    "\n",
    "# Find all .parquet files recursively\n",
    "parquet_files = list(base_folder.rglob(\"*.parquet\"))\n",
    "\n",
    "# Sort by file size (ascending)\n",
    "parquet_files_sorted = sorted(parquet_files, key=lambda p: os.path.getsize(p))\n",
    "\n",
    "# Iterate\n",
    "for file in tqdm(parquet_files_sorted, desc='File', leave='False'):\n",
    "    \n",
    "    dataset_path = str(file)\n",
    "    size_mb = f'{(os.path.getsize(dataset_path) / (1024 * 1024)):.3f} MB'\n",
    "    output_folder = Path(dataset_path.replace('/Input_Multiclass/', '/Output_Multiclass/')).parent\n",
    "    output_folder = os.path.join(str(output_folder), str(file.stem))\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    input_notebook = 'evaluator_code.ipynb'\n",
    "    output_notebook = os.path.join(output_folder, 'xgb_execution.ipynb')\n",
    "    results_filename = os.path.join(output_folder, 'xgb_summary_table.xlsx')\n",
    "\n",
    "    try:\n",
    "\n",
    "        tqdm.write(f'[{now()}] Processing | FILE = {str(file.stem):<64} | FILE_SIZE = {size_mb:<12}')\n",
    "    \n",
    "        if not Path(results_filename).exists():\n",
    "\n",
    "            parameters = dict(\n",
    "                dataset_path=dataset_path,\n",
    "                output_folder=output_folder,\n",
    "                target_column='label',\n",
    "                handle_object_cols='keep',\n",
    "                sampling_rate_global=None,\n",
    "                sampling_rate_sets=0.10,\n",
    "                sample_sets=['train'],\n",
    "                min_samples_per_class=1,\n",
    "                feature_selection_threshold=0.95,\n",
    "                sample_filtering_quantile=0.10,\n",
    "                hpo_n_trials=100,\n",
    "                hpo_timeout=900,\n",
    "                num_boost_round=300,\n",
    "                early_stopping_rounds=15,\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "                plot_param_importances=False\n",
    "            )\n",
    "\n",
    "            with open(output_notebook.replace('.ipynb', '_params.json'), 'w', encoding='utf-8') as f:\n",
    "                json.dump(parameters, f, indent=4)                \n",
    "        \n",
    "            pm.execute_notebook(input_notebook, output_notebook, parameters=parameters)\n",
    "    \n",
    "        max_config, max_f1_weighted = load_results(results_filename)\n",
    "        tqdm.write(f'[{now()}] Processed  | FILE = {str(file.stem):<64} | BEST_CONFIG = {max_config} | F1_WEIGHTED = {max_f1_weighted}')\n",
    "        \n",
    "    except (ValueError, Exception) as e:\n",
    "        tqdm.write(f'[{now()}] ERROR      | FILE = {str(file.stem):<64} | EXCEPTION = {parse_exception(e)}')\n",
    "        with open(output_notebook.replace('.ipynb', '_errors.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump({\"timestamp\": now(), \"file\": str(file), \"error\": str(e).split('\\n')}, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
